{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](../header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hls4ml: Bridging Machine Learning and FPGAs for Ultra-Fast Inference  \n",
    "\n",
    "\n",
    "üí° **High-Level Synthesis for Machine Learning (hls4ml)**  is an open-source library that transforms machine learning models into hardware descriptions optimized for FPGA deployment.\n",
    "\n",
    "**Key Features of hls4ml:** \n",
    "\n",
    "- Converts models from Keras, TensorFlow, PyTorch, and ONNX into High-Level Synthesis (HLS) projects.\n",
    "\n",
    "- Utilizes tools like Xilinx Vitis HLS and Intel HLS Compiler to generate optimized C++ code for hardware implementation.\n",
    "\n",
    "- Enhances efficiency by reducing latency and power consumption, making it ideal for AI applications in edge computing.\n",
    "\n",
    "- Supports quantization and pruning techniques to shrink model size while maintaining accuracy.\n",
    "\n",
    "\n",
    "For further details:\n",
    "\n",
    "- GitHub: https://github.com/fastmachinelearning/hls4ml\n",
    "\n",
    "- Web site: https://fastmachinelearning.org/hls4ml/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from qkeras import *\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "import hls4ml\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Vitis HLS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an initial step, the Vivado HLS or Vitis HLS (or another tool) installation directory must be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tools/Xilinx/XilinxUnified_2022/Vitis_HLS/2022.2/bin:/tools/anaconda3/envs/neuralEnv/bin:/tools/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PATH'] = '/tools/Xilinx/XilinxUnified_2022/Vitis_HLS/2022.2/bin:' + os.environ['PATH']\n",
    "os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the model (.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 18:47:12.245911: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-04-07 18:47:12.246978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2025-04-07 18:47:12.315973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-07 18:47:12.316177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.155GHz coreCount: 14 deviceMemorySize: 3.81GiB deviceMemoryBandwidth: 149.04GiB/s\n",
      "2025-04-07 18:47:12.316214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-04-07 18:47:12.356939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-04-07 18:47:12.357060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-04-07 18:47:12.379407: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-04-07 18:47:12.385267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-04-07 18:47:12.427651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-04-07 18:47:12.432805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-04-07 18:47:12.507449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-04-07 18:47:12.507724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-07 18:47:12.507896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-07 18:47:12.507988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2025-04-07 18:47:12.509391: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-07 18:47:12.510109: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-04-07 18:47:12.510188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-07 18:47:12.510299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 with Max-Q Design computeCapability: 7.5\n",
      "coreClock: 1.155GHz coreCount: 14 deviceMemorySize: 3.81GiB deviceMemoryBandwidth: 149.04GiB/s\n",
      "2025-04-07 18:47:12.510317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-04-07 18:47:12.510336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-04-07 18:47:12.510344: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-04-07 18:47:12.510351: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-04-07 18:47:12.510359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-04-07 18:47:12.510367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-04-07 18:47:12.510375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-04-07 18:47:12.510383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-04-07 18:47:12.510420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-07 18:47:12.510527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-07 18:47:12.510613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2025-04-07 18:47:12.511160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-04-07 18:47:13.456122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-04-07 18:47:13.456150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2025-04-07 18:47:13.456154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2025-04-07 18:47:13.456857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-07 18:47:13.457041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-07 18:47:13.457138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-07 18:47:13.457222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3406 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "model = load_model('../models/mnistPQKD.h5', custom_objects=co)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1_input (QDense)           (None, 5)                 3925      \n",
      "_________________________________________________________________\n",
      "relu_input (QActivation)     (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "fc1 (QDense)                 (None, 7)                 42        \n",
      "_________________________________________________________________\n",
      "relu1 (QActivation)          (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "fc2 (QDense)                 (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "relu2 (QActivation)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "output (QDense)              (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "sigmoid (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,069\n",
      "Trainable params: 4,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Level Synthesis for Machine Learning (hls4ml )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration - Granularity: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input_input, layer type: InputLayer, input shapes: [[None, 784]], output shape: [None, 784]\n",
      "Layer name: fc1_input, layer type: QDense, input shapes: [[None, 784]], output shape: [None, 5]\n",
      "Layer name: relu_input, layer type: Activation, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 5]], output shape: [None, 7]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 7]], output shape: [None, 7]\n",
      "Layer name: fc2, layer type: QDense, input shapes: [[None, 7]], output shape: [None, 10]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 10]], output shape: [None, 2]\n",
      "Layer name: sigmoid, layer type: Activation, input shapes: [[None, 2]], output shape: [None, 2]\n",
      "-----------------------------------\n",
      "Model\n",
      "  Precision:         fixed<16,6>\n",
      "  ReuseFactor:       1\n",
      "  Strategy:          Latency\n",
      "  BramFactor:        1000000000\n",
      "  TraceOutput:       False\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# granularity='model'\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='model')\n",
    "\n",
    "\n",
    "# User Configuration \n",
    "\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<8, 6>'   \n",
    "hls_config['Model']['ReuseFactor'] = 16\n",
    "hls_config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "import plotting\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(hls_config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration - Granularity: Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# granularity='name'\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "for layer in hls_config['LayerName'].keys():\n",
    "    # to collect the output from each layer\n",
    "    # hls_config['LayerName'][layer]['Trace'] = True  \n",
    "    \n",
    "    hls_config['LayerName'][layer]['ReuseFactor'] = 16\n",
    "\n",
    "hls_config['LayerName']['fc1_input_input']['Precision'] = 'ap_fixed<16, 6>'   \n",
    "hls_config['LayerName']['fc1']['Precision'] = 'ap_fixed<8, 4>'   \n",
    "\n",
    "hls_config['LayerName']['sigmoid']['Strategy'] = 'Stable'\n",
    "\n",
    "# To ensure DSPs are optimized, ‚Äúunrolled‚Äù Dense multiplication must be used before synthesizing HLS\n",
    "hls_config['Model']['Strategy'] = 'Unrolled'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(hls_config)\n",
    "print(\"-----------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hls4ml with Vitis HLS as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = hls4ml.converters.create_config(backend='vitis')\n",
    "\n",
    "# cfg['IOType']     = 'io_stream'   # Must set this if using CNNs!\n",
    "cfg['HLSConfig']  = hls_config      # HLS configuraiton\n",
    "cfg['KerasModel'] = model           # Keras model to be converted\n",
    "cfg['OutputDir']  = 'hw/'           # Project name\n",
    "cfg['Part'] = 'xc7z020clg484-1'     # PYNQ-Z1 or Zedboard: xc7z020clg484-1  ARTIX-7 xc7a35tcsg325-1  # MPSoC xczu4eg-sfvc784-2-e  xczu3eg-sfvc784-1-e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model = hls4ml.converters.keras_to_hls(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardware synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False, export=False)\n",
    "\n",
    "# hls_model.build(csim=False, export=True, bitfile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Vivado version\n",
    "# hls_config['Flows'] = ['vivado:fifo_depth_optimization']\n",
    "# hls4ml.model.optimizer.get_optimizer('vivado:fifo_depth_optimization').configure(profiling_fifo_depth=100_000)\n",
    "\n",
    "\n",
    "# Vitis version\n",
    "# hls_config['Flows'] = ['vitis:fifo_depth_optimization']\n",
    "# hls4ml.model.optimizer.get_optimizer('vitis:fifo_depth_optimization').configure(profiling_fifo_depth=100_000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Mar del Plata, Argentina - 2025\n",
    "\n",
    "Romina Soledad Molina, Ph.D. - MLab/STI ICTP, Trieste, Italy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
